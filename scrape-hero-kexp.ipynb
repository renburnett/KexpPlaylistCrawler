{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyQt4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5e2b05a730ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPyQt4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQtGui\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPyQt4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQtCore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPyQt4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQtWebKit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PyQt4'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import csv,os,json\n",
    "import requests\n",
    "from time import sleep\n",
    " \n",
    "    \n",
    "    #\n",
    "    # https://stackoverflow.com/questions/44615462/web-scraping-with-python-request-lxml-getting-data-from-ul-li\n",
    "    \n",
    "    # NEED A HEADLESS BROWSER TO GENERATE HANDLEBARS CONTENT\n",
    "    #\n",
    "    \n",
    "    # OR USE ABOVE LINK \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def KexpPlaylistParser(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.90 Safari/537.36'}\n",
    "    raw_page = requests.get(url,headers=headers)    \n",
    "    page = BeautifulSoup(raw_page.content, \"html.parser\")\n",
    "\n",
    "    \n",
    "    if page.status_code == 200:\n",
    "        print(\"good!\")\n",
    "    \n",
    "    sleep(1)\n",
    "\n",
    "    #song_divs = page.find_all(\"div\",class_=\"PlaylistItem u-mb1\")\n",
    "    song_divs = page.find_all(\"div\")\n",
    "    \n",
    "    for div in song_divs:\n",
    "        print(div)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        song_name = 'empty'\n",
    "        artist_name = 'empty'\n",
    "        album_name = 'empty'\n",
    "        time_played = 'empty'\n",
    "        \n",
    "        \n",
    "        #time, song, artist, album\n",
    "        doc = html.fromstring(page.content)\n",
    "                                \n",
    "        xpath_time = '//div[@class=\"PlaylistItem-time\"]/h5'\n",
    "#         xpath_song_name = '//div[@class=\"PlaylistItem u-mb1\"]//h3[1]/text()'\n",
    "#         xpath_song_artist = '//div[@class=\"PlaylistItem u-mb1\"]//div[@class=\"u-h3 u-mb1 u-lightWeight\"][1]/text()'\n",
    "#         xpath_song_album = '//div[@class=\"PlaylistItem u-mb1\"]//div[@class=\"u-h5\"]/text()'\n",
    "\n",
    "\n",
    "#         song_name = doc.xpath(xpath_song_name)\n",
    "#         song_artist = doc.xpath(xpath_song_artist)\n",
    "#         album_name = doc.xpath(xpath_song_album)\n",
    "        time_played = doc.xpath(xpath_time)\n",
    "    \n",
    "        #print(time_played)\n",
    "        \n",
    "        data = {\n",
    "                'song': song_name,\n",
    "                'artist': artist_name,\n",
    "                'album': album_name,\n",
    "                'time' : time_played\n",
    "                }\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    " \n",
    "def ReadAsin():\n",
    "    # AsinList = csv.DictReader(open(os.path.join(os.path.dirname(__file__),\"Asinfeed.csv\")))\n",
    "\n",
    "    extracted_data = []\n",
    "    \n",
    "    url = \"https://www.kexp.org/playlist\"\n",
    "    print(\"Processing: \"+url)\n",
    "    extracted_data.append(KexpPlaylistParser(url))\n",
    "    \n",
    "    print(extracted_data)\n",
    "    \n",
    "    sleep(2)\n",
    "    f=open('data.json','w')\n",
    "    \n",
    "    json.dump(extracted_data,f,indent=4)\n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    ReadAsin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
